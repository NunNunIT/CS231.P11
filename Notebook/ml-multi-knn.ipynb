{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2613d9ac",
   "metadata": {
    "_cell_guid": "fe25b0a4-0de2-4331-ac39-35ef365b9732",
    "_uuid": "da07681a-c14e-4172-8e84-d50ee97bccac",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:37.384429Z",
     "iopub.status.busy": "2025-01-02T15:20:37.384046Z",
     "iopub.status.idle": "2025-01-02T15:20:37.780617Z",
     "shell.execute_reply": "2025-01-02T15:20:37.779381Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.407072,
     "end_time": "2025-01-02T15:20:37.782515",
     "exception": false,
     "start_time": "2025-01-02T15:20:37.375443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6b803a",
   "metadata": {
    "_cell_guid": "60d883d0-071a-487b-81e7-5e93693e924b",
    "_uuid": "495bfbec-26af-4819-86b4-eff461413cb1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:37.799259Z",
     "iopub.status.busy": "2025-01-02T15:20:37.798800Z",
     "iopub.status.idle": "2025-01-02T15:20:40.217907Z",
     "shell.execute_reply": "2025-01-02T15:20:40.216654Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.428711,
     "end_time": "2025-01-02T15:20:40.220120",
     "exception": false,
     "start_time": "2025-01-02T15:20:37.791409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, hamming_loss\n",
    "\n",
    "# Logger setup\n",
    "logging.basicConfig(filename='model_training_log.txt', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3cea239",
   "metadata": {
    "_cell_guid": "13392367-b3c3-4aa9-aa90-91658d9c42ec",
    "_uuid": "9952e126-c6f8-4f1e-b776-e8b76c4df9a2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:40.234328Z",
     "iopub.status.busy": "2025-01-02T15:20:40.233851Z",
     "iopub.status.idle": "2025-01-02T15:20:40.239250Z",
     "shell.execute_reply": "2025-01-02T15:20:40.238370Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014562,
     "end_time": "2025-01-02T15:20:40.241176",
     "exception": false,
     "start_time": "2025-01-02T15:20:40.226614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to redirect print statements to log\n",
    "class Logger(object):\n",
    "    def __init__(self, log_file):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(log_file, 'a')\n",
    "    def write(self, message):\n",
    "        print(message)\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0a1654",
   "metadata": {
    "_cell_guid": "cb3ab75f-7957-467a-859f-8cefba321d5f",
    "_uuid": "b400462c-d827-4b14-bad9-bd84a647b68d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:40.255226Z",
     "iopub.status.busy": "2025-01-02T15:20:40.254864Z",
     "iopub.status.idle": "2025-01-02T15:20:40.259227Z",
     "shell.execute_reply": "2025-01-02T15:20:40.258061Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013353,
     "end_time": "2025-01-02T15:20:40.261041",
     "exception": false,
     "start_time": "2025-01-02T15:20:40.247688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CACHE_PATH = '/kaggle/input/cloth-image-parsed-datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18be6343",
   "metadata": {
    "_cell_guid": "c6752946-bb59-473b-a0b7-25737ca7dae6",
    "_uuid": "1be76abb-4615-46a0-a83b-2c39d2654fad",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:40.274723Z",
     "iopub.status.busy": "2025-01-02T15:20:40.274285Z",
     "iopub.status.idle": "2025-01-02T15:20:40.280899Z",
     "shell.execute_reply": "2025-01-02T15:20:40.279706Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015188,
     "end_time": "2025-01-02T15:20:40.282514",
     "exception": false,
     "start_time": "2025-01-02T15:20:40.267326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_logger(size, feature_extract):\n",
    "    log_filename = f\"logs/{size[0]}_{feature_extract.__name__}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "    os.makedirs(os.path.dirname(log_filename), exist_ok=True)\n",
    "    logger = logging.getLogger(f\"{feature_extract.__name__}_{size}\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbc1d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:40.296949Z",
     "iopub.status.busy": "2025-01-02T15:20:40.296539Z",
     "iopub.status.idle": "2025-01-02T15:20:49.180103Z",
     "shell.execute_reply": "2025-01-02T15:20:49.178404Z"
    },
    "papermill": {
     "duration": 8.893319,
     "end_time": "2025-01-02T15:20:49.182444",
     "exception": false,
     "start_time": "2025-01-02T15:20:40.289125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn-ng\r\n",
      "  Downloading scikit_multilearn_ng-0.0.8-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (1.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (1.26.4)\r\n",
      "Collecting liac-arff>=2.2.1 (from scikit-multilearn-ng)\r\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (3.3)\r\n",
      "Requirement already satisfied: python-louvain>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (0.16)\r\n",
      "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (1.0.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (1.2.2)\r\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (2.32.3)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scikit-multilearn-ng) (1.4.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->scikit-multilearn-ng) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->scikit-multilearn-ng) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->scikit-multilearn-ng) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->scikit-multilearn-ng) (2024.8.30)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.2->scikit-multilearn-ng) (3.5.0)\r\n",
      "Downloading scikit_multilearn_ng-0.0.8-py3-none-any.whl (109 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: liac-arff\r\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=7ec6d0d58a2842e35efd98cbbb1c16bd2ff9eeefbb8cf5b0098063f92340c020\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\r\n",
      "Successfully built liac-arff\r\n",
      "Installing collected packages: liac-arff, scikit-multilearn-ng\r\n",
      "Successfully installed liac-arff-2.5.0 scikit-multilearn-ng-0.0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-multilearn-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449e64b8",
   "metadata": {
    "_cell_guid": "799aac4b-be02-4f14-b3cf-83c0551e2d16",
    "_uuid": "67c4311e-84ea-42f1-b60b-de9bd18ca919",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.198593Z",
     "iopub.status.busy": "2025-01-02T15:20:49.198167Z",
     "iopub.status.idle": "2025-01-02T15:20:49.205454Z",
     "shell.execute_reply": "2025-01-02T15:20:49.204008Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018275,
     "end_time": "2025-01-02T15:20:49.208077",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.189802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = '/kaggle/input/8-labels-cloth-classification'\n",
    "IMG_DIR = os.path.join(DIR, 'imgs')\n",
    "TEST_PATH = os.path.join(DIR, 'test', 'data.json')\n",
    "TRAIN_PATH = os.path.join(DIR, 'train', 'data.json')\n",
    "VAL_PATH = os.path.join(DIR, 'val', 'data.json')\n",
    "CLASS_PATH = os.path.join(DIR, 'classes.txt')\n",
    "\n",
    "N_COMPONENTS = [0.2, 0.3, 0.5, 0.7]\n",
    "K = [5, 11, \n",
    "     # 17\n",
    "    ]\n",
    "SIZES = [\n",
    "    # 64, \n",
    "    128,\n",
    "    # 224\n",
    "]\n",
    "RESIZES = [(size, size) for size in SIZES]\n",
    "FRACTION = 1\n",
    "\n",
    "labels = [\n",
    "    \"shirt, blouse\",\n",
    "    \"top, t-shirt, sweatshirt\",\n",
    "    \"jacket\",\n",
    "    \"pants\",\n",
    "    \"skirt\",\n",
    "    \"dress\",\n",
    "    \"shoe\",\n",
    "    \"bag, wallet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b0b664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.224173Z",
     "iopub.status.busy": "2025-01-02T15:20:49.223755Z",
     "iopub.status.idle": "2025-01-02T15:20:49.228185Z",
     "shell.execute_reply": "2025-01-02T15:20:49.227088Z"
    },
    "papermill": {
     "duration": 0.014458,
     "end_time": "2025-01-02T15:20:49.229998",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.215540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "RANDOM_INDEXS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60b7cbc",
   "metadata": {
    "_cell_guid": "9e50adfa-7679-40d1-b8a9-9498a3eb0464",
    "_uuid": "ae54a838-9dac-4a8f-9bb9-b2e52bf5860b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.245983Z",
     "iopub.status.busy": "2025-01-02T15:20:49.245605Z",
     "iopub.status.idle": "2025-01-02T15:20:49.251143Z",
     "shell.execute_reply": "2025-01-02T15:20:49.249704Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015971,
     "end_time": "2025-01-02T15:20:49.253425",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.237454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_hog_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hog_features, _ = hog(\n",
    "        gray_image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm=\"L2-Hys\",\n",
    "        visualize=True,\n",
    "    )\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf4bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.269280Z",
     "iopub.status.busy": "2025-01-02T15:20:49.268933Z",
     "iopub.status.idle": "2025-01-02T15:20:49.274677Z",
     "shell.execute_reply": "2025-01-02T15:20:49.273436Z"
    },
    "papermill": {
     "duration": 0.016054,
     "end_time": "2025-01-02T15:20:49.276629",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.260575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_edge_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)  # Gradient in x direction\n",
    "    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)  # Gradient in y direction\n",
    "    sobel_edges = np.hypot(sobel_x, sobel_y)  # Compute the magnitude of gradients (edges)\n",
    "    sobel_edges = np.uint8(np.absolute(sobel_edges))  # Convert to uint8 for display and further processing\n",
    "    sobel_edges_flat = sobel_edges.flatten()\n",
    "    return sobel_edges_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55579a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.292086Z",
     "iopub.status.busy": "2025-01-02T15:20:49.291712Z",
     "iopub.status.idle": "2025-01-02T15:20:49.297526Z",
     "shell.execute_reply": "2025-01-02T15:20:49.296076Z"
    },
    "papermill": {
     "duration": 0.016142,
     "end_time": "2025-01-02T15:20:49.299984",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.283842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_both_features(image):\n",
    "    hog_features = extract_hog_features(image)\n",
    "    edge_features = extract_edge_features(image)\n",
    "    merged_features = np.concatenate((hog_features, edge_features))\n",
    "    return merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374a5b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.316322Z",
     "iopub.status.busy": "2025-01-02T15:20:49.315942Z",
     "iopub.status.idle": "2025-01-02T15:20:49.468229Z",
     "shell.execute_reply": "2025-01-02T15:20:49.466947Z"
    },
    "papermill": {
     "duration": 0.163025,
     "end_time": "2025-01-02T15:20:49.470141",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.307116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def create_pipeline(n_components, k) -> Pipeline:\n",
    "    steps = []\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    steps.append(('scaler', scaler))\n",
    "\n",
    "    pca = PCA(n_components)\n",
    "    steps.append(('pca', pca))\n",
    "\n",
    "    classifier = MLkNN(k=k)\n",
    "    steps.append(('classifier', classifier))\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd948be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.486875Z",
     "iopub.status.busy": "2025-01-02T15:20:49.486423Z",
     "iopub.status.idle": "2025-01-02T15:20:49.492264Z",
     "shell.execute_reply": "2025-01-02T15:20:49.491003Z"
    },
    "papermill": {
     "duration": 0.016884,
     "end_time": "2025-01-02T15:20:49.494733",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.477849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, hamming_loss, accuracy_score, multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)\n",
    "    hamming_loss_value = hamming_loss(y_true, y_pred)\n",
    "    conf_matrices = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # for i, label in enumerate(labels):\n",
    "    #     plt.figure(figsize=(6, 4))\n",
    "    #     sns.heatmap(conf_matrices[i], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    #     plt.title(f\"Confusion Matrix for Class {label}\")\n",
    "    #     plt.xlabel('Predicted')\n",
    "    #     plt.ylabel('True')\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "\n",
    "    metrics = {\n",
    "        \"classification_report\": report,\n",
    "        \"hamming_loss\": hamming_loss_value,\n",
    "        \"confusion_matrices\": conf_matrices\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a799be95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.511130Z",
     "iopub.status.busy": "2025-01-02T15:20:49.510733Z",
     "iopub.status.idle": "2025-01-02T15:20:49.515884Z",
     "shell.execute_reply": "2025-01-02T15:20:49.514698Z"
    },
    "papermill": {
     "duration": 0.015762,
     "end_time": "2025-01-02T15:20:49.518011",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.502249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "def convert_to_dense(matrix):\n",
    "    if issparse(matrix):\n",
    "        dense_matrix = matrix.toarray()\n",
    "    elif isinstance(matrix, np.ndarray):\n",
    "        dense_matrix = matrix\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a scipy.sparse matrix or numpy.ndarray.\")\n",
    "    \n",
    "    return dense_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d41d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.534780Z",
     "iopub.status.busy": "2025-01-02T15:20:49.534398Z",
     "iopub.status.idle": "2025-01-02T15:20:49.541830Z",
     "shell.execute_reply": "2025-01-02T15:20:49.540682Z"
    },
    "papermill": {
     "duration": 0.017519,
     "end_time": "2025-01-02T15:20:49.543750",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.526231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_from_json(json_file, img_dir, feature_extract, target_size=(64, 64)):\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    length = len(data)\n",
    "    if RANDOM_INDEXS.get(length) is None:\n",
    "        RANDOM_INDEXS[length] = random.sample(list(range(length)), int(length * FRACTION))\n",
    "        \n",
    "    # Sample the data using the indices\n",
    "    sample_data = [data[i] for i in RANDOM_INDEXS[length]]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for item in tqdm(sample_data, desc=f\"Processing data\"):\n",
    "        img_path = item[\"imgPath\"]\n",
    "        label = item[\"labels\"]  # Multi-hot encoded labels\n",
    "\n",
    "        # Construct image path\n",
    "        image_path = os.path.join(img_dir, img_path)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, target_size)\n",
    "            features = feature_extract(image)\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65e55e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.560022Z",
     "iopub.status.busy": "2025-01-02T15:20:49.559634Z",
     "iopub.status.idle": "2025-01-02T15:20:49.564058Z",
     "shell.execute_reply": "2025-01-02T15:20:49.562847Z"
    },
    "papermill": {
     "duration": 0.015507,
     "end_time": "2025-01-02T15:20:49.566467",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.550960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c149f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.582072Z",
     "iopub.status.busy": "2025-01-02T15:20:49.581691Z",
     "iopub.status.idle": "2025-01-02T15:20:49.586288Z",
     "shell.execute_reply": "2025-01-02T15:20:49.585034Z"
    },
    "papermill": {
     "duration": 0.015237,
     "end_time": "2025-01-02T15:20:49.588982",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.573745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_ = None\n",
    "best_hamming_loss_ = None\n",
    "best_k_ = None\n",
    "best_n_components = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f340eaf2",
   "metadata": {
    "_cell_guid": "625fb819-ea1b-4d04-ad5f-fb145a42c13f",
    "_uuid": "90bed9b3-15e0-4bc5-ad7f-1d56ded7cd19",
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.605891Z",
     "iopub.status.busy": "2025-01-02T15:20:49.605460Z",
     "iopub.status.idle": "2025-01-02T15:20:49.618058Z",
     "shell.execute_reply": "2025-01-02T15:20:49.616901Z"
    },
    "papermill": {
     "duration": 0.023489,
     "end_time": "2025-01-02T15:20:49.619844",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.596355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CACHE = True\n",
    "SAVED_DATA = True\n",
    "\n",
    "\n",
    "def get_path_from_file_name(file_name: str):\n",
    "    # print(f\">> CACHE_PATH: {CACHE_PATH}\")\n",
    "    if CACHE_PATH is not None:\n",
    "        file_path = os.path.join(CACHE_PATH, file_name)\n",
    "        # print(f\">> file_path: {file_path}\")\n",
    "        if os.path.exists(file_path):\n",
    "            return file_path\n",
    "    if os.path.exists(file_name):\n",
    "        return file_name\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_or_process_data(file_name, logger, size, feature_extract, data_type, load_function):\n",
    "    # print(f'>> file_name: {file_name}')\n",
    "    path = get_path_from_file_name(file_name)\n",
    "    # print(f'>> path: {path}')\n",
    "    if path is not None and CACHE:\n",
    "        logger.info(f\"Loading preprocessed {data_type} data from {path}...\")\n",
    "        data = np.load(path)\n",
    "        X, y = data[f'X_{data_type}'], data[f'y_{data_type}']\n",
    "        logger.info(f\"Loaded X_{data_type} shape: {X.shape}, y_{data_type} shape: {y.shape}\")\n",
    "    else:\n",
    "        logger.info(f\"Feature extract: {feature_extract.__name__}\")\n",
    "        logger.info(f\"Resize: {size}\")\n",
    "        logger.info(f\"Loading {data_type} data...\")\n",
    "        X, y = load_function()\n",
    "        X = X.astype('float32')\n",
    "        logger.info(f\"X_{data_type} shape: {X.shape}, y_{data_type} shape: {y.shape}\")\n",
    "\n",
    "        if SAVED_DATA:\n",
    "            logger.info(f\"Saving preprocessed {data_type} data to {file_name}...\")\n",
    "            np.savez_compressed(file_name, **{f'X_{data_type}': X, f'y_{data_type}': y})\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_combined_features(hog_file_name, edge_file_name, logger, size, data_type):\n",
    "    hog_file_path = get_path_from_file_name(hog_file_name)\n",
    "    edge_file_path = get_path_from_file_name(edge_file_name)\n",
    "    if hog_file_path is None or edge_file_path is None:\n",
    "        return None, None\n",
    "\n",
    "    logger.info(f\"Loading combined {data_type} features from {hog_file_path} and {edge_file_path}...\")\n",
    "    data_hog = np.load(hog_file_path)\n",
    "    data_edge = np.load(edge_file_path)\n",
    "    X_hog, y_hog = data_hog[f'X_{data_type}'], data_hog[f'y_{data_type}']\n",
    "    X_edge = data_edge[f'X_{data_type}']\n",
    "    X = np.concatenate((X_hog, X_edge), axis=1)\n",
    "    logger.info(f\"Combined X_{data_type} shape: {X.shape}, y_{data_type} shape: {y_hog.shape}\")\n",
    "    return X, y_hog\n",
    "\n",
    "\n",
    "def generate_file_name(size: tuple[int], feature_extract, data_type):\n",
    "    file_name = f\"data_{data_type}_{size[0]}_{feature_extract.__name__}_{FRACTION * 100}%.npz\"\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d05085a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.636662Z",
     "iopub.status.busy": "2025-01-02T15:20:49.636244Z",
     "iopub.status.idle": "2025-01-02T15:20:49.644477Z",
     "shell.execute_reply": "2025-01-02T15:20:49.643390Z"
    },
    "papermill": {
     "duration": 0.018511,
     "end_time": "2025-01-02T15:20:49.646302",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.627791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(size, feature_extract, data_type, logger):\n",
    "    if feature_extract == extract_both_features:\n",
    "        hog_file_name = generate_file_name(size, extract_hog_features, data_type)\n",
    "        edge_file_name = generate_file_name(size, extract_edge_features, data_type)\n",
    "        X, y = load_combined_features(hog_file_name, edge_file_name, logger, size, data_type)\n",
    "\n",
    "        if X is None or y is None:\n",
    "            combined_file_name = generate_file_name(size, extract_both_features, data_type)\n",
    "            X, y = load_or_process_data(\n",
    "                combined_file_name,\n",
    "                logger,\n",
    "                size,\n",
    "                feature_extract,\n",
    "                data_type,\n",
    "                lambda: (\n",
    "                    load_combined_data(data_type, feature_extract, size)\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        file_name = generate_file_name(size, feature_extract, data_type)\n",
    "        X, y = load_or_process_data(\n",
    "            file_name,\n",
    "            logger,\n",
    "            size,\n",
    "            feature_extract,\n",
    "            data_type,\n",
    "            lambda: (\n",
    "                load_combined_data(data_type, feature_extract, size)\n",
    "            )\n",
    "        )\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_combined_data(data_type, feature_extract, size):\n",
    "    if data_type == \"train\":\n",
    "        return (\n",
    "            np.concatenate([\n",
    "                load_data_from_json(TRAIN_PATH, IMG_DIR, feature_extract, size)[0],\n",
    "                load_data_from_json(VAL_PATH, IMG_DIR, feature_extract, size)[0]\n",
    "            ], axis=0),\n",
    "            np.concatenate([\n",
    "                load_data_from_json(TRAIN_PATH, IMG_DIR, feature_extract, size)[1],\n",
    "                load_data_from_json(VAL_PATH, IMG_DIR, feature_extract, size)[1]\n",
    "            ], axis=0)\n",
    "        )\n",
    "    return load_data_from_json(TEST_PATH, IMG_DIR, feature_extract, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3304d02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.662917Z",
     "iopub.status.busy": "2025-01-02T15:20:49.662509Z",
     "iopub.status.idle": "2025-01-02T15:20:49.667895Z",
     "shell.execute_reply": "2025-01-02T15:20:49.666751Z"
    },
    "papermill": {
     "duration": 0.015695,
     "end_time": "2025-01-02T15:20:49.669772",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.654077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(pipeline, filename):\n",
    "    \"\"\"Save the trained pipeline to a file.\"\"\"\n",
    "    joblib.dump(pipeline, filename)\n",
    "    logger.info(f\"Saved trained pipeline to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d2b9837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.685501Z",
     "iopub.status.busy": "2025-01-02T15:20:49.685147Z",
     "iopub.status.idle": "2025-01-02T15:20:49.690321Z",
     "shell.execute_reply": "2025-01-02T15:20:49.688912Z"
    },
    "papermill": {
     "duration": 0.015627,
     "end_time": "2025-01-02T15:20:49.692676",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.677049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    \"\"\"Load the trained pipeline from a file.\"\"\"\n",
    "    logger.info(f\"Loading trained pipeline from {filename}...\")\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d637bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.709149Z",
     "iopub.status.busy": "2025-01-02T15:20:49.708806Z",
     "iopub.status.idle": "2025-01-02T15:20:49.714096Z",
     "shell.execute_reply": "2025-01-02T15:20:49.712936Z"
    },
    "papermill": {
     "duration": 0.015112,
     "end_time": "2025-01-02T15:20:49.715868",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.700756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_and_log_metrics(y_true, y_pred, phase, n_components, k):\n",
    "    \"\"\"Evaluate predictions and log the metrics.\"\"\"\n",
    "    logger.info(f\"Evaluation {phase} data (n_components={n_components}, k={k}):\")\n",
    "    metrics = evaluate_predictions(y_true, y_pred)\n",
    "    logger.info(f\"Classification Report:\\n{metrics['classification_report']}\")\n",
    "    logger.info(f\"Hamming loss: {metrics['hamming_loss']}\")\n",
    "    logger.info(f\"Confusion matrices:\\n{metrics['confusion_matrices']}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "062fe664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.733942Z",
     "iopub.status.busy": "2025-01-02T15:20:49.733583Z",
     "iopub.status.idle": "2025-01-02T15:20:49.739782Z",
     "shell.execute_reply": "2025-01-02T15:20:49.738453Z"
    },
    "papermill": {
     "duration": 0.016554,
     "end_time": "2025-01-02T15:20:49.741597",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.725043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_save_pipeline(n_components, k, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Create, train, evaluate, and save the pipeline.\"\"\"\n",
    "    logger.info(f\"Creating and training pipeline with n_components={n_components}, k={k}...\")\n",
    "    pipeline = create_pipeline(n_components, k)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    y_train_pred = convert_to_dense(pipeline.predict(X_train))\n",
    "    evaluate_and_log_metrics(y_train, y_train_pred, \"train\", n_components, k)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_test_pred = convert_to_dense(pipeline.predict(X_test))\n",
    "    metrics = evaluate_and_log_metrics(y_test, y_test_pred, \"test\", n_components, k)\n",
    "\n",
    "    return pipeline, metrics['hamming_loss']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147c07ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.757482Z",
     "iopub.status.busy": "2025-01-02T15:20:49.757132Z",
     "iopub.status.idle": "2025-01-02T15:20:49.761763Z",
     "shell.execute_reply": "2025-01-02T15:20:49.760637Z"
    },
    "papermill": {
     "duration": 0.014474,
     "end_time": "2025-01-02T15:20:49.763491",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.749017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c00d28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.779514Z",
     "iopub.status.busy": "2025-01-02T15:20:49.779178Z",
     "iopub.status.idle": "2025-01-02T15:20:49.788121Z",
     "shell.execute_reply": "2025-01-02T15:20:49.786967Z"
    },
    "papermill": {
     "duration": 0.019364,
     "end_time": "2025-01-02T15:20:49.790182",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.770818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_models(K, N_COMPONENTS, X_train, y_train, X_test, y_test, feature_extract, size, FRACTION, CACHE_PATH, CACHE):\n",
    "    \"\"\"Process models for various configurations, optimized for memory usage.\"\"\"\n",
    "    best_model_info = {\n",
    "        'model': None,\n",
    "        'hamming_loss': float('-inf'),\n",
    "        'n_components': None,\n",
    "        'k': None\n",
    "    }\n",
    "    \n",
    "    for n_components in N_COMPONENTS:\n",
    "        for k in K:\n",
    "            # Free memory before each iteration\n",
    "            gc.collect()\n",
    "            \n",
    "            try:\n",
    "                pipeline, hamming_loss = train_and_save_pipeline(\n",
    "                    n_components, k, X_train, y_train, X_test, y_test\n",
    "                )\n",
    "                \n",
    "                if hamming_loss > best_model_info['hamming_loss']:\n",
    "                    # Delete previous best model if it exists\n",
    "                    if best_model_info['model'] is not None:\n",
    "                        del best_model_info['model']\n",
    "                        gc.collect()\n",
    "                    \n",
    "                    best_model_info.update({\n",
    "                        'model': pipeline,\n",
    "                        'hamming_loss': hamming_loss,\n",
    "                        'n_components': n_components,\n",
    "                        'k': k\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing model with n_components={n_components}, k={k}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "    if best_model_info['model'] is None:\n",
    "        logger.warning(\"No valid models were processed\")\n",
    "        return\n",
    "        \n",
    "    model_file_name = (f\"models/model_{size[0]}_{feature_extract.__name__}_\"\n",
    "                      f\"{best_model_info['n_components']}_{best_model_info['k']}_\"\n",
    "                      f\"{FRACTION * 100}%.joblib\")\n",
    "    \n",
    "    try:\n",
    "        save_model(best_model_info['model'], model_file_name)\n",
    "        logger.info(f\"Successfully saved model: {model_file_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save model: {str(e)}\")\n",
    "    finally:\n",
    "        del best_model_info\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c7e6213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.806574Z",
     "iopub.status.busy": "2025-01-02T15:20:49.806122Z",
     "iopub.status.idle": "2025-01-02T15:20:49.810788Z",
     "shell.execute_reply": "2025-01-02T15:20:49.809760Z"
    },
    "papermill": {
     "duration": 0.015959,
     "end_time": "2025-01-02T15:20:49.813410",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.797451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure the folder exists, creating it if necessary\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d1b44cb",
   "metadata": {
    "_cell_guid": "5d8d11ac-37fb-48b8-89ec-c4dc734d96c7",
    "_uuid": "bcc75472-62cd-4c81-9b2e-858fb172df71",
    "execution": {
     "iopub.execute_input": "2025-01-02T15:20:49.830226Z",
     "iopub.status.busy": "2025-01-02T15:20:49.829899Z"
    },
    "papermill": {
     "duration": 14108.872998,
     "end_time": "2025-01-02T19:15:58.693409",
     "exception": false,
     "start_time": "2025-01-02T15:20:49.820411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 15:20:49,836 - INFO - Loading combined train features from /kaggle/input/cloth-image-parsed-datasets/data_train_128_extract_hog_features_100%.npz and /kaggle/input/cloth-image-parsed-datasets/data_train_128_extract_edge_features_100%.npz...\n",
      "2025-01-02 15:21:25,338 - INFO - Combined X_train shape: (39701, 24484), y_train shape: (39701, 8)\n",
      "2025-01-02 15:21:25,353 - INFO - Loading combined test features from /kaggle/input/cloth-image-parsed-datasets/data_test_128_extract_hog_features_100%.npz and /kaggle/input/cloth-image-parsed-datasets/data_test_128_extract_edge_features_100%.npz...\n",
      "2025-01-02 15:21:29,247 - INFO - Combined X_test shape: (4412, 24484), y_test shape: (4412, 8)\n",
      "2025-01-02 15:21:29,354 - INFO - Creating and training pipeline with n_components=0.2, k=5...\n",
      "2025-01-02 16:45:28,659 - INFO - Evaluation train data (n_components=0.2, k=5):\n",
      "2025-01-02 16:45:28,829 - INFO - Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           shirt, blouse       0.62      0.12      0.21      5495\n",
      "top, t-shirt, sweatshirt       0.68      0.50      0.58     14551\n",
      "                  jacket       0.63      0.19      0.29      6938\n",
      "                   pants       0.64      0.37      0.47     11127\n",
      "                   skirt       0.64      0.08      0.14      4551\n",
      "                   dress       0.69      0.60      0.64     16822\n",
      "                    shoe       0.81      0.89      0.85     21527\n",
      "             bag, wallet       0.64      0.20      0.30      6214\n",
      "\n",
      "               micro avg       0.72      0.51      0.60     87225\n",
      "               macro avg       0.67      0.37      0.43     87225\n",
      "            weighted avg       0.70      0.51      0.55     87225\n",
      "             samples avg       0.65      0.52      0.55     87225\n",
      "\n",
      "2025-01-02 16:45:28,830 - INFO - Hamming loss: 0.18851225409939296\n",
      "2025-01-02 16:45:28,831 - INFO - Confusion matrices:\n",
      "[[[33784   422]\n",
      "  [ 4810   685]]\n",
      "\n",
      " [[21715  3435]\n",
      "  [ 7259  7292]]\n",
      "\n",
      " [[31967   796]\n",
      "  [ 5604  1334]]\n",
      "\n",
      " [[26214  2360]\n",
      "  [ 6968  4159]]\n",
      "\n",
      " [[34950   200]\n",
      "  [ 4203   348]]\n",
      "\n",
      " [[18376  4503]\n",
      "  [ 6759 10063]]\n",
      "\n",
      " [[13733  4441]\n",
      "  [ 2452 19075]]\n",
      "\n",
      " [[32806   681]\n",
      "  [ 4980  1234]]]\n",
      "2025-01-02 16:45:32,475 - INFO - Evaluation test data (n_components=0.2, k=5):\n",
      "2025-01-02 16:45:32,500 - INFO - Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           shirt, blouse       0.18      0.04      0.06       620\n",
      "top, t-shirt, sweatshirt       0.43      0.31      0.36      1625\n",
      "                  jacket       0.17      0.05      0.08       804\n",
      "                   pants       0.29      0.17      0.22      1220\n",
      "                   skirt       0.16      0.02      0.04       483\n",
      "                   dress       0.45      0.39      0.42      1844\n",
      "                    shoe       0.73      0.81      0.77      2427\n",
      "             bag, wallet       0.23      0.07      0.11       693\n",
      "\n",
      "               micro avg       0.52      0.36      0.43      9716\n",
      "               macro avg       0.33      0.23      0.26      9716\n",
      "            weighted avg       0.43      0.36      0.38      9716\n",
      "             samples avg       0.46      0.37      0.39      9716\n",
      "\n",
      "2025-01-02 16:45:32,502 - INFO - Hamming loss: 0.2685573436083409\n",
      "2025-01-02 16:45:32,503 - INFO - Confusion matrices:\n",
      "[[[3694   98]\n",
      "  [ 598   22]]\n",
      "\n",
      " [[2116  671]\n",
      "  [1120  505]]\n",
      "\n",
      " [[3403  205]\n",
      "  [ 761   43]]\n",
      "\n",
      " [[2687  505]\n",
      "  [1011  209]]\n",
      "\n",
      " [[3878   51]\n",
      "  [ 473   10]]\n",
      "\n",
      " [[1692  876]\n",
      "  [1131  713]]\n",
      "\n",
      " [[1278  707]\n",
      "  [ 472 1955]]\n",
      "\n",
      " [[3565  154]\n",
      "  [ 646   47]]]\n",
      "2025-01-02 16:45:32,603 - INFO - Creating and training pipeline with n_components=0.2, k=11...\n",
      "2025-01-02 18:11:43,421 - INFO - Evaluation train data (n_components=0.2, k=11):\n",
      "2025-01-02 18:11:43,573 - INFO - Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           shirt, blouse       0.57      0.02      0.03      5495\n",
      "top, t-shirt, sweatshirt       0.63      0.33      0.44     14551\n",
      "                  jacket       0.61      0.04      0.08      6938\n",
      "                   pants       0.59      0.17      0.26     11127\n",
      "                   skirt       0.55      0.03      0.05      4551\n",
      "                   dress       0.63      0.49      0.55     16822\n",
      "                    shoe       0.84      0.80      0.82     21527\n",
      "             bag, wallet       0.60      0.05      0.09      6214\n",
      "\n",
      "               micro avg       0.72      0.38      0.50     87225\n",
      "               macro avg       0.63      0.24      0.29     87225\n",
      "            weighted avg       0.66      0.38      0.43     87225\n",
      "             samples avg       0.57      0.40      0.44     87225\n",
      "\n",
      "2025-01-02 18:11:43,575 - INFO - Hamming loss: 0.21140525427571094\n",
      "2025-01-02 18:11:43,576 - INFO - Confusion matrices:\n",
      "[[[34136    70]\n",
      "  [ 5403    92]]\n",
      "\n",
      " [[22322  2828]\n",
      "  [ 9682  4869]]\n",
      "\n",
      " [[32567   196]\n",
      "  [ 6633   305]]\n",
      "\n",
      " [[27261  1313]\n",
      "  [ 9239  1888]]\n",
      "\n",
      " [[35042   108]\n",
      "  [ 4421   130]]\n",
      "\n",
      " [[18087  4792]\n",
      "  [ 8591  8231]]\n",
      "\n",
      " [[14829  3345]\n",
      "  [ 4410 17117]]\n",
      "\n",
      " [[33285   202]\n",
      "  [ 5911   303]]]\n",
      "2025-01-02 18:11:47,238 - INFO - Evaluation test data (n_components=0.2, k=11):\n",
      "2025-01-02 18:11:47,263 - INFO - Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           shirt, blouse       0.06      0.00      0.00       620\n",
      "top, t-shirt, sweatshirt       0.44      0.24      0.31      1625\n",
      "                  jacket       0.27      0.02      0.03       804\n",
      "                   pants       0.27      0.08      0.12      1220\n",
      "                   skirt       0.04      0.00      0.00       483\n",
      "                   dress       0.45      0.34      0.39      1844\n",
      "                    shoe       0.78      0.72      0.75      2427\n",
      "             bag, wallet       0.24      0.02      0.03       693\n",
      "\n",
      "               micro avg       0.58      0.30      0.39      9716\n",
      "               macro avg       0.32      0.18      0.21      9716\n",
      "            weighted avg       0.44      0.30      0.33      9716\n",
      "             samples avg       0.45      0.31      0.34      9716\n",
      "\n",
      "2025-01-02 18:11:47,264 - INFO - Hamming loss: 0.2532581595648232\n",
      "2025-01-02 18:11:47,265 - INFO - Confusion matrices:\n",
      "[[[3775   17]\n",
      "  [ 619    1]]\n",
      "\n",
      " [[2298  489]\n",
      "  [1233  392]]\n",
      "\n",
      " [[3571   37]\n",
      "  [ 790   14]]\n",
      "\n",
      " [[2926  266]\n",
      "  [1121   99]]\n",
      "\n",
      " [[3907   22]\n",
      "  [ 482    1]]\n",
      "\n",
      " [[1801  767]\n",
      "  [1210  634]]\n",
      "\n",
      " [[1504  481]\n",
      "  [ 688 1739]]\n",
      "\n",
      " [[3684   35]\n",
      "  [ 682   11]]]\n",
      "2025-01-02 18:11:47,367 - INFO - Creating and training pipeline with n_components=0.3, k=5...\n"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "for size in RESIZES:\n",
    "    for feature_extract in [\n",
    "        # extract_hog_features, extract_edge_features, \n",
    "        extract_both_features\n",
    "    ]:\n",
    "        logger = create_logger(size, feature_extract)\n",
    "        X_train, y_train = process_data(size, feature_extract, \"train\", logger)\n",
    "        X_test, y_test = process_data(size, feature_extract, \"test\", logger)\n",
    "\n",
    "        process_models(K, N_COMPONENTS, X_train, y_train, X_test, y_test, feature_extract, size, FRACTION, CACHE_PATH, CACHE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1357a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6374330,
     "sourceId": 10298524,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6395075,
     "sourceId": 10328271,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14123.699738,
   "end_time": "2025-01-02T19:15:58.799950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-02T15:20:35.100212",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
